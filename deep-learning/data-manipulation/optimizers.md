:[https://keras.io/optimizers/](https://keras.io/optimizers/)

[http://ruder.io/optimizing-gradient-descent/](http://ruder.io/optimizing-gradient-descent/)

[http://cs231n.github.io/neural-networks-3/](http://cs231n.github.io/neural-networks-3/)

[https://blog.algorithmia.com/introduction-to-optimizers/](https://blog.algorithmia.com/introduction-to-optimizers/)

https://blog.paperspace.com/intro-to-optimization-in-deep-learning-gradient-descent/



**Optimizers** update the weight parameters to minimize the loss function. Loss function acts as guides to the terrain telling optimizer if it is moving in the right direction to reach the bottom of the valley, the global minimum.

Eg: Batch gradient descent, Stochastic gradient descent, Mini-batch gradient descent

